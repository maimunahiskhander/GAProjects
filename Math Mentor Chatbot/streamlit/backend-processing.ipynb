{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b83a224c",
   "metadata": {},
   "source": [
    "# Capstone Project: Building a Simple Math Chatbot (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 2, we perform the backend processing for the chatbot."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56ee5543",
   "metadata": {},
   "source": [
    "![Retrieval Augmented Generation(RAG)](https://miro.medium.com/v2/resize:fit:720/format:webp/1*UyhiO87T-hejRhqI7EwvgA.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Import libraries, API and set filepath](#Import-libraries,-API-and-set-filepath)\n",
    "2. [Load the data](#Load-the-Data)\n",
    "3. [Build index](#Build-Index)\n",
    "4. [Train generation](#Train-generation)\n",
    "5. [Eval generation](#Eval-generation)\n",
    "6. [Initial evaluation](#Initial-evaluation)\n",
    "7. [Using GPT-4 to Generate Training Data](#Using-GPT-4-to-Generate-Training-Data)\n",
    "8. [Create Fine Tuned Engine](#Create-Fine-Tuned-Engine)\n",
    "9. [Evaluating Fine Tuned Engine](#Evaluating-Fine-Tuned-Engine)\n",
    "10. [Exploring Differences](#Exploring-Differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc96d46",
   "metadata": {},
   "source": [
    "## Import libraries, API and set filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9888248b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %pip install llama-index==0.8.64 pypdf sentence-transformers ragas openai\n",
    "# Operating System Interface\n",
    "import os\n",
    "\n",
    "# Load Environment Variables\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Random Number Operations\n",
    "import random\n",
    "\n",
    "# Machine Learning and AI\n",
    "import openai\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "# Data Handling and Datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "# Document and Vector Store Indexing\n",
    "from llama_index import Document, GPTVectorStoreIndex, ServiceContext\n",
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "# Web Scraping and Directory Reading\n",
    "from llama_index.readers import BeautifulSoupWebReader, SimpleDirectoryReader\n",
    "\n",
    "# Evaluation and Dataset Generation\n",
    "from llama_index.evaluation import DatasetGenerator\n",
    "\n",
    "# Callbacks and Fine-Tuning Handlers for AI Models\n",
    "from llama_index.callbacks import OpenAIFineTuningHandler, CallbackManager\n",
    "\n",
    "# Evaluation Metrics and Utilities\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy, faithfulness\n",
    "\n",
    "# Display Utilities for Notebooks\n",
    "from llama_index.response.notebook_utils import display_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load api key\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd1be0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set filepath to my data directory \n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.join(current_dir, \"./data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99211f6b",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "According to [LlamaIndex's documentation](https://gpt-index.readthedocs.io/en/latest/examples/data_connectors/simple_directory_reader.html), the `SimpleDirectoryReader` is the most commonly used data connector that just works. Simply pass in a input directory or a list of files. It will select the best file reader based on the file extensions. \n",
    "\n",
    "In this use case here, there are PDFs and html pages from the latest release from HPB and MOH, which are not included in gpt-3.5-turbo's pretraining of up to Sep 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13e2d763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['66fe35d1-1297-48f1-bf9e-7b7dd664a38b', 'f095173a-7331-4c88-be1d-dfd5d36ba3a2', '64f3556e-c116-487d-8702-f892c0597d1b', 'cccebb0e-2008-4cd6-a329-044cb84ee721', '0df45f31-4473-4a72-8815-6dd849ce3de7', 'a92023d2-ddd7-4776-ba7c-e42db8aba7b9', '55860270-c5dd-45e7-a5cb-9d4490e9d5ac', '5239d46e-f76c-4eb1-8879-6ec51fd62094', 'efcac31f-ada9-480d-a9e8-cc2bd9e5ffc5', 'eab4aefa-6568-4ded-9e2f-2bb84a16901e', 'f40d5444-baa9-4ba3-8c6c-f55dd95fd365', '015e6724-8277-4094-adcb-6af9a1d12b03', '7ee6f6af-e11e-4f67-950f-1cd5c3c0b65c', '04bf9fba-cc3f-4bd6-b82d-2d8ae2f057cd', '2779b428-3d90-4d8e-80d5-6da2b997a130', 'fc904f2d-6e38-4f88-99d7-1bef264aebd2', '193a9b80-950e-4e07-a5c4-64c77e319d62', 'a39e88e4-1b8c-44e8-bf86-582c18f83f1c', 'd9dbe155-6bfe-4ea0-b6cd-ecef4b2a91dc', '2ee4c90e-b1ed-4341-a5f7-8c19f0bc3796', '05cee5c5-808c-4ebb-be01-0550af732b2e', 'fa2e7745-362e-4d4f-a4df-dec2264dab2c', '3ab87c95-9bfd-4e39-ac7c-d4329de6f264', '5355a144-08eb-452b-8eb4-bdcc7b106cee', 'dfd94765-f060-4dbe-8f40-6928c7f6d181', 'd7110b41-8496-4ad7-be85-13d61ef166ce', '14b63010-4fe9-40be-97d6-4b722204ba7a', '941cedab-c6ce-4252-a33d-a34079157f26', '5b1285b0-9a09-4b70-b0e1-54e780d7d414', '5f6f8153-b60f-404e-a723-39dc356bf5c4', 'a4b3f958-6b3d-4233-b495-dc017d96ba9c', '193e0780-827a-4f7f-8faf-d6045604b552', '4a63d7b2-c052-4d9e-9a2b-f3fe70d13297', '5582c99f-c724-447a-9421-a348e01ea63e', '29792b92-acf6-4db9-8855-3251cae7360b', '68dcccff-5f7b-4cf1-8259-06e45a9bfad7', '2958ea97-da24-4cb0-9205-b36d35303dce', 'd68883ae-8edb-4fe1-900e-b22c70bcb462', 'b65ddaec-c385-44f0-8c24-164d307e47a6', '99399212-d5fc-4153-b95b-c4b449c2b96f', '94a85593-4396-4a88-be1a-c808ba28ead9', '4107a952-bc34-4684-9bc4-f2bd1ea9689b', 'd59f94a0-1b66-4b20-85ae-ee0139cfb630', '624f1c15-a629-4c6e-9820-7076908748e0', 'f92f5285-56e2-4acb-b27b-e335dd275296', '78f0b94f-e993-49a8-9cc8-2b1f25709dc3', '4a6b1372-a310-44b9-98b2-9348efe2b774', 'bc955446-4bfb-4eaf-9460-7e2eb6cdeb18', '77ca6a97-4341-4946-bc33-2e2bbf21e265', 'e03644da-103e-421d-9bca-708fbeff7cda', 'c7afd226-70b2-49b4-9823-2a3ed7daa8d1', 'c8d8562d-21a3-4dc7-82e6-5f49db2ac52e', '86977864-426c-4c80-9145-de318652c3c2', '869b1213-50f8-435f-827e-064ba571310a', 'd20315dd-f51f-41b4-b9c6-9579aca18dff', 'e32a3f6a-ac36-4bb4-998f-e7843c47dec9', 'd2fa0ac4-3995-4223-966d-34dfbd7ef673', '41db8e22-0b9a-4fd5-b101-063b66054504', '5a92b32b-918a-41ac-ace9-d6e1d61acbde', 'a0e751d9-c2f9-4fb1-86e3-87f3ddcaf1a9', 'e28e097f-0f14-4621-985a-43edc272944a', 'dabc7ffd-25be-4988-861d-eeaf277337b2', '50615e21-90ca-4f08-84e4-e178ba3cde00', '5a79d6ca-02b5-4352-b6c7-d14cb051434f', '3f1b1648-afad-42c4-9027-b0aa9db022b7', 'cd2947a2-cd3b-4dc5-992f-8acf49540f63', '6864aadc-c643-496e-a0f6-3b2bce838f93', 'f484ad52-963d-43d8-8463-fca60c9d2cb5', '70159c4a-44ed-43da-8bea-e78f24ecc7a1', '3200a2a7-78c7-4577-921a-1a5842fdef2d', '09afb26f-8c22-4f55-a5bf-beea55984555', 'ea17117b-a4c7-468d-9157-df359a7ff020', 'af86ffed-1b1f-4d5e-9ab5-3d1d083f2f23', '81533b16-3e53-4246-93f8-7d925bf5b2e6', 'c33a2e3e-eeb2-4ff0-8d02-646c4f15b83a', 'a3ba3385-7d37-49dc-b47e-965ac82c1ef0', '7fee677a-b507-429d-a72a-c7f550c4a448', '4bce6cad-9b4d-405a-a4a1-60f98842a0a8', '596218db-e89c-40fa-8c4e-f470e0ae3c27', '22692782-2009-46c6-81a5-b0257019cec7']\n",
      "Loaded 80 docs\n"
     ]
    }
   ],
   "source": [
    "filename_fn = lambda filename: {'file_name': filename}\n",
    "pdfhtml_docs = SimpleDirectoryReader(input_dir=data_dir, exclude_hidden=True, file_metadata=filename_fn).load_data()\n",
    "print([x.doc_id for x in pdfhtml_docs])\n",
    "print(f\"Loaded {len(pdfhtml_docs)} docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba98350",
   "metadata": {},
   "source": [
    "## Build index\n",
    "\n",
    "With all the data loaded, we can construct the index for the chatbot. There are 4 types of indexing: Summary index, VectorStore Index, Tree Index and Keyword Table Index. Here we are using VectorStore Index, which is also one of the most common types of indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5884ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more info on service context, refer to \n",
    "# https://gpt-index.readthedocs.io/en/latest/core_modules/supporting_modules/service_context.html\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0) # degree of randomness from 0 to 1. \n",
    ")\n",
    "docs = pdfhtml_docs\n",
    "index = GPTVectorStoreIndex.from_documents(documents=docs, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a86885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the output as a vector store so that we can refer to this \n",
    "# instead of running the embedding model above again\n",
    "\n",
    "index.storage_context.persist(persist_dir=\"./data/index.vecstore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d7bea1",
   "metadata": {},
   "source": [
    " We will be fine tuning the GPT model.\n",
    "\n",
    "Step 1: Generate a training and evaluation dataset using GPT-4.  \n",
    "Step 2: Use GPT-3.5-turbo on the evaluation questions to get our baseline performance.  \n",
    "Step 3: Generate another set of training dataset using GPT-4.  \n",
    "Step 4: Fine tune the GPT-3.5-turbo-0613 model on the openai website using the training dataset from Step 3.  \n",
    "Step 5: Use the fine tuned model to evaluate the evaluation questions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4f3a75",
   "metadata": {},
   "source": [
    "## Train generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b839c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the documents\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(docs)\n",
    "\n",
    "gpt_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-4\", temperature=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "009c3944",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_gen_query=(\n",
    "    \"Write a primary school mathematics multiple choice question in the following form:\\\n",
    "    Question; A) option1 ; B) option2; C) option3 (correct); D) option4.\"\n",
    "    )\n",
    "# find out more about question generation from \n",
    "# https://gpt-index.readthedocs.io/en/latest/examples/evaluation/QuestionGeneration.html\n",
    "\n",
    "dataset_generator = DatasetGenerator.from_documents(\n",
    "    docs[:50],\n",
    "    question_gen_query=question_gen_query,\n",
    "    service_context=gpt_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "56238a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  40  questions\n"
     ]
    }
   ],
   "source": [
    "questions = dataset_generator.generate_questions_from_nodes(num=40)\n",
    "print(\"Generated \", len(questions), \" questions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "addee976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Simplify the expression 12x - 4x + 3 - 2x + 1. A) 6x + 4 B) 10x + 2 C) 6x + 2 (correct) D) 10x + 4.\n",
      "What is the sum of the first two common multiples of 4 and 6? A) 24 ; B) 60; C) 36 (correct); D) 48.\n",
      "What is the result of multiplying 3 260 by 100? A) 3 260 ; B) 32 600; C) 326 000 (correct); D) 3 260 000.\n",
      "What is the value of 10x+5-3x when x=6? A) 45 B) 55 C) 65 (correct) D) 75\n",
      "In the number 392 504, the digit 9 is in which place? A) hundreds; B) ten thousands; C) thousands (correct); D) hundred thousands.\n",
      "How many hundredths are there in 0.87? A) 0.08; B) 0.8; C) 87 (correct); D) 80.\n",
      "What is the numeral representation of \"five million, nine thousand and sixty\"? A) 5 009 006; B) 5 009 060 (correct); C) 5090 006; D) 5090 060.\n",
      "Question: What is the decimal representation of 3 ones, 4 tenths, and 7 thousandths? A) 3.47 ; B) 3.407 (correct); C) 4.37; D) 3.74.\n",
      "What is the area of a semicircle with a diameter of 84 cm? (Take pi = 22/7); A) 264 cm²; B) 528 cm²; C) 2772 cm² (correct); D) 5544 cm².\n",
      "Which number rounds off to 5200 when rounded to the nearest hundred? A) 5099 ; B) 5159; C) 5299 (correct); D) 5310.\n",
      "Question: Round off 4567 to the nearest ten. A) 4500; B) 4560; C) 4570 (correct); D) 4577.\n",
      "Question: In the number 456.789, which digit is in the hundredths place?; A) 4; B) 5; C) 8 (correct); D) 9.\n",
      "What is the equivalent of 3040 grams in kilograms and grams? A) 3kg 4g ; B) 3kg 40g (correct); C) 30kg 4g; D) 30kg 40g.\n",
      "Question: Convert 5 km 50 m into km. A) 5050m ; B) 5.005 km; C) 5.05 km (correct); D) 5.5 km.\n",
      "Question: If 4,050 x 500 = 405 x ___ x 5, what number should replace the blank? A) 50 ; B) 500; C) 5,000 (correct); D) 50,000.\n",
      "Question: Convert 25 litres and 45 ml into ml. A) 25045 ml; B) 2545 ml; C) 25000 ml; D) 25450 ml (correct).\n",
      "Question: A triangle has a height of 48 cm and a base of 51 cm. What is the area of the triangle? A) 998 cm^2 ; B) 1024 cm^2; C) 1224 cm^2 (correct); D) 2448 cm^2.\n",
      "What is the sum of all the factors of 9? A) 12 ; B) 16; C) 13 (correct); D) 15.\n",
      "Question: What is the correct representation of 4 hundreds, 7 tenths, and 2 thousandths? A) 400.720 ; B) 470.200 ; C) 400.072 (correct); D) 407.200.\n",
      "Question: Round off 76.843 to 2 decimal places. A) 76.84 ; B) 76.85 (correct); C) 76.80; D) 77.00.\n",
      "Question: Convert 3050 grams into kilograms. What is the correct conversion?; A) 3.05 kg ; B) 30.5 kg; C) 305 kg; D) 0.305 kg (correct).\n",
      "What is the sum of 50 tens, 50 hundredths, and 5 thousandths? A) 50.505 ; B) 50.055; C) 500.505 (correct); D) 500.055\n",
      "In the number 4 683 170, which digit is in the hundred thousands place? A) 1 ; B) 3; C) 6 (correct); D) 8.\n",
      "Question: Lisa purchased a house for $256,745. What is this amount when rounded off to the nearest $1000?; A) $256,000 ; B) $256,700; C) $257,000 (correct); D) $256,800.\n",
      "What does the first digit, 5, represent in the number 534 987? A) 500 B) 5000 C) 500 000 (correct) D) 50000\n",
      "What is the value of the digit 4 in the number 456 102? A) 4 B) 40 C) 400 D) 400 000 (correct)\n",
      "Question: Convert 510 meters into a percentage of 4.25 kilometers. A) 0.12% ; B) 1.2% ; C) 12% (correct); D) 120%\n",
      "What is the value of 8x-3+5x when x=3? A) 21 B) 31 C) 39 D) 49\n",
      "What number should be added to 4000 000 + 5000 + 300 + 20 + 1 to get 4 605 321? A) 600 ; B) 6 000; C) 600 000 (correct); D) 60 000.\n",
      "In the number 45.32, which digit is in the tenths place? A) 4 B) 5 C) 3 (correct) D) 2\n",
      "If y = 8, what is the value of 15y + 10 - 3y? A) 42 ; B) 96 ; C) 106 (correct) ; D) 120.\n",
      "What is 80% of 160? A) 32 ; B) 72; C) 128 (correct); D) 12 800.\n",
      "What is the average of the numbers 108, 305, and 79? A) 123 ; B) 164 (correct); C) 246; D) 492\n",
      "What is 26.05 kg in kilograms and grams? A) 2kg 605g ; B) 26kg 5g; C) 26 kg 50g (correct); D) 26 kg 500g.\n",
      "Anthony bought a box of candies for $8. If the box contained 40 candies, how much did each candy cost? A) 5 cents ; B) 20 cents (correct); C) 32 cents; D) 50 cents.\n",
      "Which of the following numbers is the largest? A) 325 154 ; B) 325541; C) 352 154 (correct); D) 352 145.\n",
      "Question: What is the missing number in the following equation: 345 678 = 300 000 + ______ + 40 000 + 5 000 + 600 + 70 + 8; A) 3 000 ; B) 30 000; C) 300 000 (correct); D) 3 000 000.\n",
      "Question: If x=3 and y = 4, what is the value of 6xy + y?; A) 72; B) 76; C) 78 (correct); D) 80.\n",
      "How many hundreds are there in 123 000? A) 230 ; B) 1230; C) 12300 (correct); D) 2300.\n",
      "Question: Round off 4.267 to the nearest hundredth. A) 4.2 ; B) 4.26; C) 4.27 (correct); D) 4.30.\n"
     ]
    }
   ],
   "source": [
    "with open(\"train_questions.txt\", \"w\") as f:\n",
    "    for question in questions:\n",
    "        f.write(question + \"\\n\")\n",
    "        print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = 'train_questions.txt'\n",
    "output_file_path = 'modified_train_questions.txt'\n",
    "\n",
    "def postprocess(input_file_path, output_file_path):\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        modified_lines = [line.replace(\"Question:\", \"\").strip() for line in file]\n",
    "\n",
    "    with open(output_file_path, 'w') as new_file:\n",
    "        for line in modified_lines:\n",
    "            new_file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eafadd",
   "metadata": {},
   "source": [
    "Screenshot of modified train questions:\n",
    "![](../streamlit/images/modtrain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a366a4bd",
   "metadata": {},
   "source": [
    "## Eval generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3b0e58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generator = DatasetGenerator.from_documents(\n",
    "    docs[\n",
    "        50:\n",
    "    ],\n",
    "    question_gen_query=question_gen_query,\n",
    "    service_context=gpt_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f50d7307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  30  questions\n"
     ]
    }
   ],
   "source": [
    "questions = dataset_generator.generate_questions_from_nodes(num=40)\n",
    "print(\"Generated \", len(questions), \" questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Screenshot of evaluation questions:\n",
    "![](../streamlit/images/eval.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c62a9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"eval_questions.txt\", \"w\") as f:\n",
    "    for question in questions:\n",
    "        f.write(question + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = 'eval_questions.txt'\n",
    "output_file_path = 'modified_eval_questions.txt'\n",
    "\n",
    "postprocess(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Screenshot of modified evaluation questions:\n",
    "![](../streamlit/images/modeval.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 80\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of documents:\", len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0324ad69",
   "metadata": {},
   "source": [
    "## Initial Evaluation\n",
    "\n",
    "For this evaluation with GPT-3.5-turbo Query Engine, we will be using the [`ragas` evaluation library](https://github.com/explodinggradients/ragas).\n",
    "\n",
    "For this notebook, we will be using the following two metrics:\n",
    "\n",
    "- `answer_relevancy` - This measures how relevant is the generated answer to the prompt. If the generated answer is incomplete or contains redundant information the score will be low. This is quantified by working out the chance of an LLM generating the given question using the generated answer. Values range (0,1), higher the better.  \n",
    "- `faithfulness` - This measures the factual consistency of the generated answer against the given context. This is done using a multi step paradigm that includes creation of statements from the generated answer followed by verifying each of these statements against the context. The answer is scaled to (0,1) range. Higher the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "849d3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "with open(\"modified_eval_questions.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        questions.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "78c5f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the context window to 2048 tokens so that refine is used\n",
    "gpt_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0), context_window=2048\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs, service_context=gpt_context)\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7e119ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "answers = []\n",
    "\n",
    "for question in questions:\n",
    "    response = query_engine.query(question)\n",
    "    contexts.append([x.node.get_content() for x in response.source_nodes])\n",
    "    answers.append(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the remainder when 3908 is divided by 7? A) 2 ; B) 3 (correct); C) 5; D) 6',\n",
       " 'What is the simplified form of the expression 6 + 8y + 7 - 5y? A) 1+ 13y ; B) 13 + 18y; C) 13 + 3y (correct); D) 13 - 3y.',\n",
       " 'What is the approximate weight of a completely filled can of soft drink? A) 30g; B) 300g (correct); C) 3kg; D) 30kg.',\n",
       " 'What is the product of 353 and 19? A) 334 ; B) 372; C) 6770 (correct); D) 6707.',\n",
       " 'Mr. Lee exchanged a $5 note for 10 coins. All the coins had the same value. What was the value of each coin?; A) 10 cents; B) 20 cents; C) 50 cents (correct); D) 1 dollar.',\n",
       " 'Marilyn bought 20 packets of tissue paper for $4. How much did each packet of tissue paper cost? A) $0.50 ; B) $0.20; C) $0.05 (correct); D) $0.02.',\n",
       " 'In the ratio 5:__ = 100:120, what is the missing number? A) 10 B) 15 C) 25 (correct) D) 30',\n",
       " 'How many thousands are there in 4 500 000?; A) 45 ; B) 450; C) 4 500 (correct); D) 45 000.',\n",
       " '700 305 is ____ more than 680 305. A) 200 tens B) 2 thousands C) 20 thousands (correct) D) 2 ten thousands.',\n",
       " 'What is the area of a triangle with a height of 25 cm and a base of 20 cm? A) 500 square cm; B) 900 square cm; C) 250 square cm (correct); D) 750 square cm.']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d27a0ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:55<00:00, 27.95s/it]\n",
      "/opt/homebrew/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/opt/homebrew/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:35<00:00, 47.83s/it]\n",
      "/opt/homebrew/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/opt/homebrew/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ragas_score': 0.7685, 'answer_relevancy': 0.8517, 'faithfulness': 0.7000}\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "    }\n",
    ")\n",
    "\n",
    "result = evaluate(ds, [answer_relevancy, faithfulness])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a66544e",
   "metadata": {},
   "source": [
    "## Using GPT-4 to Generate Training Data\n",
    "\n",
    "Here, we use GPT-4 and the `OpenAIFineTuningHandler` to collect data that we want to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "86d9b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_handler = OpenAIFineTuningHandler()\n",
    "callback_manager = CallbackManager([finetuning_handler])\n",
    "\n",
    "gpt_4_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-4\", temperature=0),\n",
    "    context_window=2048,  # limit the context window artifically to test refine process\n",
    "    callback_manager=callback_manager,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6e69c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "with open(\"modified_train_questions.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        questions.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "db75f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs, service_context=gpt_4_context)\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "39ee8890",
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in questions:\n",
    "    response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1c6ac",
   "metadata": {},
   "source": [
    "## Create Fine Tuned Engine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "270f5516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 40 examples to finetuning_events.jsonl\n"
     ]
    }
   ],
   "source": [
    "finetuning_handler.save_finetuning_events(\"finetuning_events.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](../streamlit/images/ftmodel.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c804716",
   "metadata": {},
   "source": [
    "## Evaluating Fine Tuned Engine\n",
    "\n",
    "After some time, your model will be done training!\n",
    "\n",
    "The next step is running our fine-tuned model on our eval dataset again to measure any performance increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1094c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "with open(\"eval_questions.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        questions.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"ft:gpt-3.5-turbo-0613:personal::8Qufx558\",temperature=0), context_window=2048\n",
    ")\n",
    "index = VectorStoreIndex.from_documents(docs, service_context=ft_context)\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "376fa2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "answers = []\n",
    "\n",
    "for question in questions:\n",
    "    response = query_engine.query(question)\n",
    "    contexts.append([x.node.get_content() for x in response.source_nodes])\n",
    "    answers.append(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ab41cba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:53<00:00, 26.90s/it]\n",
      "/opt/homebrew/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/opt/homebrew/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [11:27<00:00, 343.91s/it]\n",
      "/opt/homebrew/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/opt/homebrew/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ragas_score': 0.8150, 'answer_relevancy': 0.8922, 'faithfulness': 0.7500}\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.from_dict(\n",
    "    {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "    }\n",
    ")\n",
    "\n",
    "result = evaluate(ds, [answer_relevancy, faithfulness])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f4a75",
   "metadata": {},
   "source": [
    "| Model            | RAGAS Score | Answer Relevancy   | Faithfulness     |\n",
    "|:----------------:|:-----------:|:------------------:|:--------------:|\n",
    "| GPT-3.5-Turbo    | 0.7685      | 0.8517             | 0.7000         |\n",
    "| Finetuned        | 0.8150      | 0.8922             | 0.7500         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b789ce",
   "metadata": {},
   "source": [
    "## Exploring Differences\n",
    "\n",
    "Let's quickly compare the differences in responses, to demonstrate that fine tuning did indeed change something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72a4e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce5b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "with open(\"modified_eval_questions.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        questions.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00a403a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 305 is ____ more than 680 305. A) 200 tens B) 2 thousands C) 20 thousands (correct) D) 2 ten thousands.\n"
     ]
    }
   ],
   "source": [
    "print(questions[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0782afdb",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daebb298",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_35_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.2),\n",
    "    context_window=2048,  # limit the context window artifically to test refine process\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f92a9de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The answer is B) 2 thousands."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(service_context=gpt_35_context)\n",
    "\n",
    "response = query_engine.query(questions[8])\n",
    "\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** 3 hundreds"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "custom_query=\"What is the value of 3 in 3560? A) 3 thousands B) 3 hundreds C) 3 tens D) 3 ones\"\n",
    "response = query_engine.query(custom_query)\n",
    "\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfbfcb5",
   "metadata": {},
   "source": [
    "## Fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "579b2c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_context = ServiceContext.from_defaults(\n",
    "    #llm=ft_llm,\n",
    "    llm=OpenAI(model=\"ft:gpt-3.5-turbo-0613:personal::8Qufx558\",temperature=0),\n",
    "    context_window=2048,  # limit the context window artifically to test refine process\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eee391a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The correct answer is C) 20 thousands."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(service_context=ft_context)\n",
    "\n",
    "response = query_engine.query(questions[8])\n",
    "\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The value of 3 in 3560 is 3 thousands."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(custom_query)\n",
    "\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is indeed a difference between the two models. The fine-tuned model is more accurate in its answer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
